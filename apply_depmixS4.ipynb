{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb753e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "import numpy as np\n",
    "\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ef857",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(\"depmixS4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc675b",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524674b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/directory/file_name.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab950c",
   "metadata": {},
   "source": [
    "#### Bin the channels - categories from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c318249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outgoing call'] = df['Outgoing call'].apply(lambda x: 2 if x>0 else 1)\n",
    "df['Incoming call'] = df['Incoming call'].apply(lambda x: 2 if x>0 else 1)\n",
    "df['Social media App'] = df['Social media App'].apply(lambda x: 2 if x>0 else 1)\n",
    "df['Communication App'] = df['Communication App'].apply(lambda x: 2 if x>0 else 1)\n",
    "df['Phone Usage'] = df['Phone Usage'].apply(lambda x: 2 if x>0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fddcc39",
   "metadata": {},
   "source": [
    "#### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98667fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  If has_data is 0, set all other columns to NaN\n",
    "df.loc[df['has_data'] == 0, 'Outgoing call'] = np.nan\n",
    "df.loc[df['has_data'] == 0, 'Incoming call'] = np.nan\n",
    "df.loc[df['has_data'] == 0, 'Social media App'] = np.nan\n",
    "df.loc[df['has_data'] == 0, 'Communication App'] = np.nan\n",
    "df.loc[df['has_data'] == 0, 'Phone Usage'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f282b33",
   "metadata": {},
   "source": [
    "### Group model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c7af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode hour using onehot encoding\n",
    "df = df.sort_values(by=['Hour'])  # sorting to make sure hours always get same assignment regardless of which is the first value in the df\n",
    "onehot_hour = pd.get_dummies(df['Hour'], dtype=float, prefix=\"onehot_hour\", drop_first=True)\n",
    "df = pd.concat([df, onehot_hour], axis=1)\n",
    "df = df.sort_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cbfdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training/testing split:\n",
    "df_training = df[df['Testing1_Training0']==0]\n",
    "df_subset = df_training[['ID', 'Hour', 'Outgoing call', 'Incoming call', 'Social media App', 'Communication App', 'Phone Usage','onehot_hour_1',\n",
    "       'onehot_hour_2', 'onehot_hour_3', 'onehot_hour_4', 'onehot_hour_5',\n",
    "       'onehot_hour_6', 'onehot_hour_7', 'onehot_hour_8', 'onehot_hour_9',\n",
    "       'onehot_hour_10', 'onehot_hour_11', 'onehot_hour_12', 'onehot_hour_13',\n",
    "       'onehot_hour_14', 'onehot_hour_15', 'onehot_hour_16', 'onehot_hour_17',\n",
    "       'onehot_hour_18', 'onehot_hour_19', 'onehot_hour_20', 'onehot_hour_21',\n",
    "       'onehot_hour_22', 'onehot_hour_23']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa3a8fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get vector containing lengths of time series for each training participant\n",
    "IDs = list(df_subset['ID'].unique())\n",
    "sequence_length = []\n",
    "for ID in IDs:\n",
    "    length = len(df_subset[df_subset['ID']==ID])\n",
    "    sequence_length.append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee449e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i df_subset,sequence_length\n",
    "# Train model\n",
    "df_subset[df_subset == 'NaN'] <- NA\n",
    "\n",
    "start_time <- Sys.time()\n",
    "colnames(df_subset) <- c('ID', 'Hour', 'Outgoing.call', 'Incoming.call', 'Social.media.App', 'Communication.App', 'Phone.Usage','onehot_hour_1','onehot_hour_2', 'onehot_hour_3', 'onehot_hour_4', 'onehot_hour_5', 'onehot_hour_6', 'onehot_hour_7', 'onehot_hour_8', 'onehot_hour_9', 'onehot_hour_10', 'onehot_hour_11', 'onehot_hour_12', 'onehot_hour_13', 'onehot_hour_14', 'onehot_hour_15', 'onehot_hour_16', 'onehot_hour_17', 'onehot_hour_18', 'onehot_hour_19', 'onehot_hour_20', 'onehot_hour_21', 'onehot_hour_22', 'onehot_hour_23')\n",
    "n_states <- 2\n",
    "mod <- depmix(list(Outgoing.call ~ 1 \n",
    "                   , Incoming.call ~ 1\n",
    "                   , Social.media.App ~ 1\n",
    "                   , Communication.App ~ 1\n",
    "                   , Phone.Usage ~ 1\n",
    "                  ), data = df_subset, nstates = n_states,\n",
    " family = list(multinomial(link=\"identity\")\n",
    "               , multinomial(link=\"identity\"), multinomial(link=\"identity\")\n",
    "               , multinomial(link=\"identity\"), multinomial(link=\"identity\")\n",
    "              ),\n",
    "              ntimes=as.vector(sequence_length)\n",
    "              , transition=~onehot_hour_1+onehot_hour_2+ onehot_hour_3+ onehot_hour_4+ onehot_hour_5+onehot_hour_6+ onehot_hour_7+ onehot_hour_8+ onehot_hour_9+onehot_hour_10+ onehot_hour_11+ onehot_hour_12+ onehot_hour_13+onehot_hour_14+ onehot_hour_15+ onehot_hour_16+ onehot_hour_17+onehot_hour_18+ onehot_hour_19+ onehot_hour_20+ onehot_hour_21+onehot_hour_22+ onehot_hour_23  # time-varying covariates for transition probabilities\n",
    "             )\n",
    "\n",
    "fm <- fit(mod)\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)\n",
    "\n",
    "filename = paste('/directory/file_name_', as.character(n_states), '.rda', sep='')\n",
    "saveRDS(fm, file =filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74f8346",
   "metadata": {},
   "source": [
    "### Quantifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480080b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "fm <- readRDS('/directory/file_name.rda')\n",
    "print(logLik(fm))\n",
    "print(summary(fm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828d512d",
   "metadata": {},
   "source": [
    "### Predict hidden state sequence for training segments (participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf75695",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "pst_viterbi <- posterior(fm,type=\"viterbi\")\n",
    "group_state_sequence <- pst_viterbi['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b4cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hidden state sequence\n",
    "training_overall_state_sequence = r['group_state_sequence']\n",
    "df_training_overall_state_sequence = pd.DataFrame(columns=['State'])\n",
    "df_training_overall_state_sequence['State'] = list(training_overall_state_sequence)[0]\n",
    "df_training_overall_state_sequence.to_csv('/directory/file_name.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9028e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If loading hidden state sequence\n",
    "df_training_overall_state_sequence = pd.read_csv('/directory/file_name.csv')\n",
    "df_training_overall_state_sequence.rename(columns={\"State\": \"state\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the periods where data was missing from df_training_overall_state_sequence\n",
    "# Combine the state sequence in df with rest of data, drop has_data=0 rows, then take out state sequence column so can get new length per p\n",
    "df_training_overall_state_sequence['has_data'] = df_training['has_data']\n",
    "df_training_overall_state_sequence['ID'] = df_training['ID']\n",
    "df_training_overall_state_sequence = df_training_overall_state_sequence.loc[df_training_overall_state_sequence['has_data']==1]\n",
    "\n",
    "# Also calculate remaining lengths for sequences\n",
    "IDs = list(df_training_overall_state_sequence['ID'].unique())\n",
    "sequence_length_training = []\n",
    "for ID in IDs:\n",
    "    length = len(df_training_overall_state_sequence[df_training_overall_state_sequence['ID']==ID])\n",
    "    sequence_length_training.append(length)\n",
    "    \n",
    "df_training_overall_state_sequence = df_training_overall_state_sequence.drop(['has_data','ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253c817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i df_training_overall_state_sequence\n",
    "group_state_sequence <- df_training_overall_state_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1fc275",
   "metadata": {},
   "source": [
    "#### Training segment (participant) dwell times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb86d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i sequence_length_training\n",
    "all_training_segment_dwell_times <- list()\n",
    "start <- 1\n",
    "for (s in sequence_length_training)\n",
    "    {\n",
    "    end <- start + s - 1\n",
    "    segment_state_sequence <- group_state_sequence[start:end,1]    \n",
    "    dwell_time_state1 <- 100 * length(which(segment_state_sequence==1))/length(segment_state_sequence)\n",
    "    dwell_time_state2 <- 100 * length(which(segment_state_sequence==2))/length(segment_state_sequence)\n",
    "    segment_dwell_times <- list(dwell_time_state1,dwell_time_state2)#,dwell_time_state3,dwell_time_state4)\n",
    "    print(segment_dwell_times)\n",
    "    all_training_segment_dwell_times <- append(all_training_segment_dwell_times,segment_dwell_times) \n",
    "    start <- end + 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69165132",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_segment_dwell_times = r['all_training_segment_dwell_times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwell_times_state1 = all_training_segment_dwell_times[0:len(all_training_segment_dwell_times):2]\n",
    "dwell_times_state2 = all_training_segment_dwell_times[1:len(all_training_segment_dwell_times):2]\n",
    "dwell_times_state1 = [dwell_times_state1[i][0] for i in range(len(dwell_times_state1))]\n",
    "dwell_times_state2 = [dwell_times_state2[i][0] for i in range(len(dwell_times_state2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dwell_times = pd.DataFrame(columns=['ID', 'SFS', 'LONELINESS', 'AGE', 'LABEL', 'DATASET', 'dwell_times_state1','dwell_times_state2', 'Testing1_Training0'])\n",
    "df_training_ID_unique = df_training.drop_duplicates(subset=['ID'])\n",
    "df_dwell_times['ID'] = df_training_ID_unique['ID']\n",
    "df_dwell_times['SFS'] = df_training_ID_unique['SFS']\n",
    "df_dwell_times['LONELINESS'] = df_training_ID_unique['LONELINESS']\n",
    "df_dwell_times['AGE'] = df_training_ID_unique['AGE']\n",
    "df_dwell_times['LABEL'] = df_training_ID_unique['LABEL']\n",
    "df_dwell_times['DATASET'] = df_training_ID_unique['DATASET']\n",
    "df_dwell_times['dwell_times_state1'] = dwell_times_state1\n",
    "df_dwell_times['dwell_times_state2'] = dwell_times_state2\n",
    "df_dwell_times['Testing1_Training0'] = 0\n",
    "df_dwell_times.to_csv('/directory/file_name.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd21edb",
   "metadata": {},
   "source": [
    "### Predict hidden state sequence for testing segments (participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dde5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = df[(df['Testing1_Training0']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e54369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vector containing lengths of time series for each participant\n",
    "df_testing = df_testing[['ID', 'Hour', 'has_data', 'Outgoing call', 'Incoming call', 'Social media App', 'Communication App', 'Phone Usage','onehot_hour_1',\n",
    "       'onehot_hour_2', 'onehot_hour_3', 'onehot_hour_4', 'onehot_hour_5',\n",
    "       'onehot_hour_6', 'onehot_hour_7', 'onehot_hour_8', 'onehot_hour_9',\n",
    "       'onehot_hour_10', 'onehot_hour_11', 'onehot_hour_12', 'onehot_hour_13',\n",
    "       'onehot_hour_14', 'onehot_hour_15', 'onehot_hour_16', 'onehot_hour_17',\n",
    "       'onehot_hour_18', 'onehot_hour_19', 'onehot_hour_20', 'onehot_hour_21',\n",
    "       'onehot_hour_22', 'onehot_hour_23']]\n",
    "sequence_length_testing = []\n",
    "for ID in list(df_testing['ID'].unique()):\n",
    "    length = len(df_testing[df_testing['ID']==ID])\n",
    "    sequence_length_testing.append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaefd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R\n",
    "# initial_probabilities <- getpars(fm)[1:2]\n",
    "# transition_matrix <- getpars(fm)[3:6]\n",
    "# emission_probabilities <- getpars(fm)[7:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f294dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i df_testing,sequence_length_testing\n",
    "df_testing[df_testing == 'NaN'] <- NA\n",
    "colnames(df_testing) <- c('ID', 'Hour', 'has_data', 'Outgoing.call', 'Incoming.call', 'Social.media.App', 'Communication.App', 'Phone.Usage','onehot_hour_1','onehot_hour_2', 'onehot_hour_3', 'onehot_hour_4', 'onehot_hour_5',        'onehot_hour_6', 'onehot_hour_7', 'onehot_hour_8', 'onehot_hour_9',        'onehot_hour_10', 'onehot_hour_11', 'onehot_hour_12', 'onehot_hour_13',        'onehot_hour_14', 'onehot_hour_15', 'onehot_hour_16', 'onehot_hour_17',        'onehot_hour_18', 'onehot_hour_19', 'onehot_hour_20', 'onehot_hour_21',        'onehot_hour_22', 'onehot_hour_23')\n",
    "n_states <- 2\n",
    "mod_testing <- depmix(list(Outgoing.call ~ 1\n",
    "                   , Incoming.call ~ 1\n",
    "                   , Social.media.App ~ 1\n",
    "                   , Communication.App ~ 1\n",
    "                   , Phone.Usage ~ 1\n",
    "                  ), data = df_testing, nstates = n_states,\n",
    " family = list(multinomial(link=\"identity\")\n",
    "               , multinomial(link=\"identity\"), multinomial(link=\"identity\")\n",
    "               , multinomial(link=\"identity\"), multinomial(link=\"identity\")\n",
    "              ),\n",
    "              ntimes=as.vector(sequence_length_testing)\n",
    "              , transition= ~ onehot_hour_1+onehot_hour_2+ onehot_hour_3+ onehot_hour_4+ onehot_hour_5+onehot_hour_6+ onehot_hour_7+ onehot_hour_8+ onehot_hour_9+onehot_hour_10+ onehot_hour_11+ onehot_hour_12+ onehot_hour_13+onehot_hour_14+ onehot_hour_15+ onehot_hour_16+ onehot_hour_17+onehot_hour_18+ onehot_hour_19+ onehot_hour_20+ onehot_hour_21+onehot_hour_22+ onehot_hour_23  # time-varying covariates # runs with ~Hour but need transform\n",
    "             )\n",
    "mod_testing <- setpars(mod_testing,getpars(fm))  # Use parameters from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa03526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "pst_viterbi <- posterior(mod_testing,type=\"viterbi\")\n",
    "testing_overall_state_sequence <- pst_viterbi['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00287aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hidden state sequence\n",
    "testing_overall_state_sequence = r['testing_overall_state_sequence']\n",
    "testing_overall_state_sequence = testing_overall_state_sequence[:]\n",
    "df_testing_overall_state_sequence = pd.DataFrame(columns=['State'])\n",
    "df_testing_overall_state_sequence['State'] = list(testing_overall_state_sequence)[0][:-1]\n",
    "df_testing_overall_state_sequence.to_csv('/directory/file_name.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5b160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the periods where data was missing from df_training_overall_state_sequence\n",
    "# Combine the state sequence in df with rest of data, drop has_data=0 rows, then take out state sequence column so can get new length per p\n",
    "df_testing_overall_state_sequence['has_data'] = list(df_testing['has_data'])\n",
    "df_testing_overall_state_sequence['ID'] = list(df_testing['ID'])\n",
    "print(len(df_testing['ID'].unique()))\n",
    "df_testing_overall_state_sequence = df_testing_overall_state_sequence.loc[df_testing_overall_state_sequence['has_data']==1]\n",
    "\n",
    "# Also calculate remaining lengths for sequences\n",
    "IDs = list(df_testing_overall_state_sequence['ID'].unique())\n",
    "print(len(IDs))\n",
    "sequence_length_testing = []\n",
    "for ID in IDs:\n",
    "    length = len(df_testing_overall_state_sequence[df_testing_overall_state_sequence['ID']==ID])\n",
    "    sequence_length_testing.append(length)\n",
    "    \n",
    "df_testing_overall_state_sequence = df_testing_overall_state_sequence.drop(['has_data','ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5aba50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i sequence_length_testing\n",
    "all_testing_segment_dwell_times <- list()\n",
    "start <- 1\n",
    "for (s in sequence_length_testing)\n",
    "    {\n",
    "    end <- start + s - 1\n",
    "    testing_state_sequence <- testing_overall_state_sequence[start:end,1]    \n",
    "    dwell_time_state1 <- 100 * length(which(testing_state_sequence==1))/length(testing_state_sequence)\n",
    "    dwell_time_state2 <- 100 * length(which(testing_state_sequence==2))/length(testing_state_sequence)\n",
    "    segment_dwell_times <- list(dwell_time_state1,dwell_time_state2)#,dwell_time_state3,dwell_time_state4)\n",
    "    print(segment_dwell_times)\n",
    "    all_testing_segment_dwell_times <- append(all_testing_segment_dwell_times,segment_dwell_times) \n",
    "    start <- end + 1\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460338c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_testing_segment_dwell_times = r['all_testing_segment_dwell_times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8408f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwell_times_state1 = all_testing_segment_dwell_times[0:len(all_testing_segment_dwell_times):2]\n",
    "dwell_times_state2 = all_testing_segment_dwell_times[1:len(all_testing_segment_dwell_times):2]\n",
    "dwell_times_state1 = [dwell_times_state1[i][0] for i in range(len(dwell_times_state1))]\n",
    "dwell_times_state2 = [dwell_times_state2[i][0] for i in range(len(dwell_times_state2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = df[(df['Testing1_Training0']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dwell_times = pd.DataFrame(columns=['ID', 'SFS', 'LONELINESS', 'LABEL', 'AGE', 'SEX', 'RACE',\n",
    "       'EDUCATION YEARS', 'COUNTRY', 'DATASET', 'dwell_times_state1', 'dwell_times_state2', 'Testing1_Training0'])\n",
    "df_testing_ID_unique = df_testing.drop_duplicates(subset=['ID'])\n",
    "df_dwell_times['ID'] = df_testing_ID_unique['ID']\n",
    "df_dwell_times['SFS'] = df_testing_ID_unique['SFS']\n",
    "df_dwell_times['LONELINESS'] = df_testing_ID_unique['LONELINESS']\n",
    "df_dwell_times['LABEL'] = df_testing_ID_unique['LABEL']\n",
    "df_dwell_times['AGE'] = df_testing_ID_unique['AGE']\n",
    "df_dwell_times['SEX'] = df_testing_ID_unique['SEX']\n",
    "df_dwell_times['RACE'] = df_testing_ID_unique['RACE']\n",
    "df_dwell_times['EDUCATION YEARS'] = df_testing_ID_unique['EDUCATION YEARS']\n",
    "df_dwell_times['COUNTRY'] = df_testing_ID_unique['COUNTRY']\n",
    "df_dwell_times['DATASET'] = df_testing_ID_unique['DATASET']\n",
    "df_dwell_times['dwell_times_state1'] = dwell_times_state1\n",
    "df_dwell_times['dwell_times_state2'] = dwell_times_state2\n",
    "df_dwell_times['Testing1_Training0'] = 1\n",
    "df_dwell_times.to_csv('/directory/file_name.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e84735",
   "metadata": {},
   "source": [
    "### Inclusion of individual transition coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d2ae0b",
   "metadata": {},
   "source": [
    "If individual transition coefficients were included in the model (i.e. +ID in the transition formula) then the coefficients can be converted to probabilities using this function, where the mean probability is calculated across the day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e5cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "convert_coefficients_to_probabilities <- function(from_state_n_intercepts,from_state_n_id_coefficients_matrix, from_state_n_hour_coefficients_matrix){\n",
    "    #To get probabilities for each person per hour and then do mean\n",
    "    # from_state_n_intercepts contains the intercepts, from_state_n_id_coefficients_matrix contains the coefficients for each ID, and from_state_n_hour_coefficients_matrix contains the coefficients for each hour\n",
    "    #Empty vector for probs for each hour\n",
    "    into_state_1_probabilities <- c()\n",
    "    into_state_2_probabilities <- c()\n",
    "    into_state_3_probabilities <- c()\n",
    "    into_state_4_probabilities <- c()\n",
    "    into_state_5_probabilities <- c()\n",
    "    # Add intercepts to each value \n",
    "    from_state_n_added_intercept_to_each_coefficient <- from_state_n_id_coefficients_matrix + rep(from_state_n_intercepts, each = nrow(from_state_n_id_coefficients_matrix))\n",
    "    # Add back in intercept row as use this for first participant\n",
    "    from_state_n_added_intercept_to_each_coefficient <- rbind(from_state_n_intercepts, from_state_n_added_intercept_to_each_coefficient)\n",
    "    \n",
    "    # Do probs for hour zero:\n",
    "    # Exponentiate\n",
    "    from_state_n_added_intercept_to_each_coefficient_exp <- exp(from_state_n_added_intercept_to_each_coefficient)\n",
    "    # Make denominator (sum each row, don't do +1 as exp'ing 0 gives the +1)\n",
    "    from_state_n_added_intercept_to_each_coefficient_denominator <- apply(from_state_n_added_intercept_to_each_coefficient_exp, 1, sum) # the '1,sum' bit means sum across each row\n",
    "    # Divide by denominator\n",
    "    trans_probs <- from_state_n_added_intercept_to_each_coefficient_exp/from_state_n_added_intercept_to_each_coefficient_denominator  \n",
    "    into_state_1_probabilities <- cbind(into_state_1_probabilities, trans_probs[,1])\n",
    "    into_state_2_probabilities <- cbind(into_state_2_probabilities, trans_probs[,2])\n",
    "    into_state_3_probabilities <- cbind(into_state_3_probabilities, trans_probs[,3])\n",
    "    into_state_4_probabilities <- cbind(into_state_4_probabilities, trans_probs[,4])\n",
    "    into_state_5_probabilities <- cbind(into_state_5_probabilities, trans_probs[,5])   \n",
    "    # Then need to add in coefficient for all other hours\n",
    "    for (i in 1:23) {\n",
    "        # Get hour coefficients\n",
    "        from_state_n_hour_coefficient <- from_state_n_hour_coefficients_matrix[i,]\n",
    "        # Add hour coefficients to the ID+intercept matrix\n",
    "        from_state_n_added_hour_to_each_coefficient <- from_state_n_added_intercept_to_each_coefficient + rep(from_state_n_hour_coefficient, each = nrow(from_state_n_added_intercept_to_each_coefficient))\n",
    "        # For transitions into state 1 need to do differently. So set 1st column back to 0 so it will still give 1 when exponentiate (and therefore provide correct value in denominator)\n",
    "        # Exponentiate\n",
    "        from_state_n_added_hour_to_each_coefficient_exp <- exp(from_state_n_added_hour_to_each_coefficient)\n",
    "        # Make denominator \n",
    "        from_state_n_added_hour_to_each_coefficient_denominator <- apply(from_state_n_added_hour_to_each_coefficient_exp, 1, sum) # the '1,sum' bit means sum across each row\n",
    "        # Divide by denominator\n",
    "        trans_probs <- from_state_n_added_hour_to_each_coefficient_exp/from_state_n_added_hour_to_each_coefficient_denominator  \n",
    "        # Store each probability\n",
    "        into_state_1_probabilities <- cbind(into_state_1_probabilities, trans_probs[,1])\n",
    "        into_state_2_probabilities <- cbind(into_state_2_probabilities, trans_probs[,2])\n",
    "        into_state_3_probabilities <- cbind(into_state_3_probabilities, trans_probs[,3])\n",
    "        into_state_4_probabilities <- cbind(into_state_4_probabilities, trans_probs[,4])\n",
    "        into_state_5_probabilities <- cbind(into_state_5_probabilities, trans_probs[,5])\n",
    "    }\n",
    "    #Calculate means\n",
    "    into_state_1_probabilities_mean <- apply(into_state_1_probabilities, 1, mean)\n",
    "    into_state_2_probabilities_mean <- apply(into_state_2_probabilities, 1, mean)\n",
    "    into_state_3_probabilities_mean <- apply(into_state_3_probabilities, 1, mean)\n",
    "    into_state_4_probabilities_mean <- apply(into_state_4_probabilities, 1, mean)\n",
    "    into_state_5_probabilities_mean <- apply(into_state_5_probabilities, 1, mean)\n",
    "\n",
    "    mean_trans_probs <- cbind(into_state_1_probabilities_mean, into_state_2_probabilities_mean, into_state_3_probabilities_mean, into_state_4_probabilities_mean, into_state_5_probabilities_mean)\n",
    "\n",
    "    return(mean_trans_probs)\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
